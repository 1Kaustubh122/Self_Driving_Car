{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\WORKSTATION2\\Miniconda3\\envs\\carla_rl\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\WORKSTATION2\\Miniconda3\\envs\\carla_rl\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import zmq\n",
    "import pickle\n",
    "import numpy as np\n",
    "import gymnasium as gym\n",
    "from gymnasium import spaces\n",
    "from stable_baselines3 import PPO\n",
    "from process_frame import process_frame\n",
    "from stable_baselines3.common.callbacks import CheckpointCallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Location:\n",
    "    def __init__(self, x, y, z=0.0):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.z = z\n",
    "\n",
    "    def distance(self, other):\n",
    "        return np.sqrt((self.x - other.x)**2 + (self.y - other.y)**2 + (self.z - other.z)**2)\n",
    "\n",
    "def quaternion_to_yaw(q):\n",
    "    w, x, y, z = q[\"w\"], q[\"x\"], q[\"y\"], q[\"z\"]\n",
    "    siny_cosp = 2 * (w * z + x * y)\n",
    "    cosy_cosp = 1 - 2 * (y**2 + z**2)\n",
    "    yaw = np.arctan2(siny_cosp, cosy_cosp)\n",
    "    return yaw \n",
    "\n",
    "def normalize_angle(angle):\n",
    "    while angle > np.pi:\n",
    "        angle -= 2 * np.pi\n",
    "    while angle < -np.pi:\n",
    "        angle += 2 * np.pi\n",
    "    return angle\n",
    "\n",
    "def decode_image(image_bytes):\n",
    "    np_arr = np.frombuffer(image_bytes, dtype=np.uint8)\n",
    "    img = cv2.imdecode(np_arr, cv2.IMREAD_COLOR)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CarlaEnv(gym.Env):\n",
    "    def __init__(self, port=6501):\n",
    "        super(CarlaEnv, self).__init__()\n",
    "        self.port = port\n",
    "        self.context = zmq.Context()\n",
    "        self.socket = self.context.socket(zmq.REQ)\n",
    "        self.socket.connect(f\"tcp://localhost:{self.port}\")\n",
    "\n",
    "        self.action_space = spaces.Box(low=-1, high=1, shape=(2,), dtype=np.float32)\n",
    "                                                 # [dist, angle, speed, lane_dev, obs_prox]\n",
    "        self.observation_space = spaces.Box(low=np.array([-np.inf, -np.pi, 0, -1, 0]),\n",
    "                                            high=np.array([np.inf, np.pi, np.inf, 1, 1]),\n",
    "                                            dtype=np.float32)\n",
    "        \n",
    "        self.route = None\n",
    "        self.wp_index = 0\n",
    "\n",
    "        self.previous_location = None\n",
    "        self.previous_timestamp = None\n",
    "        self.previous_distance = None\n",
    "\n",
    "        self.max_steps = 2000\n",
    "        self.step_count = 0\n",
    "\n",
    "\n",
    "    def reset(self, seed = None, options = None):\n",
    "        self.socket.send(pickle.dumps({\"command\": \"reset\"}))\n",
    "        \n",
    "        response = pickle.loads(self.socket.recv())\n",
    "        # print(response)\n",
    "        if response[\"status\"] != \"reset done\":\n",
    "            raise RuntimeError(f\"Server reset failed check port cur port {self.port}\")\n",
    "        \n",
    "        obs = response[\"observation\"] \n",
    "        self.route = [Location(x, y) for [x, y] in response[\"route\"]]\n",
    "        self.wp_index = 0\n",
    "\n",
    "        image = decode_image(obs[\"image\"])\n",
    "        _, lane_deviation, obstacle_proximity = process_frame(image)\n",
    "        state = self.get_state(obs, lane_deviation, obstacle_proximity)\n",
    "\n",
    "        self.previous_location = self.get_current_location(obs)\n",
    "        self.previous_timestamp = obs[\"timestamp\"]\n",
    "        self.previous_distance = self.get_distance_to_waypoint(obs)\n",
    "        self.previous_steer = 0\n",
    "        self.step_count=0\n",
    "\n",
    "        return state, {}\n",
    "    \n",
    "    def step(self, action):\n",
    "        self.socket.send(pickle.dumps({\"action\": action.tolist()}))\n",
    "        obs = pickle.loads(self.socket.recv())\n",
    "\n",
    "        image = decode_image(obs[\"image\"])\n",
    "        processed_image, lane_deviation, obstacle_proximity = process_frame(image)\n",
    "        state = self.get_state(obs, lane_deviation, obstacle_proximity)\n",
    "\n",
    "        reward = self.compute_reward(obs, lane_deviation, obstacle_proximity, action[0])\n",
    "\n",
    "        if obs[\"collision\"] is not None:\n",
    "            print(\"Collision detected, respawning...\")\n",
    "            state, _ = self.reset()\n",
    "            reward -= 100\n",
    "\n",
    "        else:\n",
    "            state = self.get_state(obs, lane_deviation, obstacle_proximity)\n",
    "\n",
    "        terminated = self.is_terminated(obs)\n",
    "        truncated = self.is_truncated()\n",
    "\n",
    "        self.step_count += 1\n",
    "\n",
    "        self.previous_location = self.get_current_location(obs)\n",
    "        self.previous_timestamp = obs[\"timestamp\"]\n",
    "        self.previous_distance = self.get_distance_to_waypoint(obs)\n",
    "        self.previous_steer = action[0]\n",
    "\n",
    "        return state, reward, terminated, truncated, {}\n",
    "    \n",
    "    def get_current_location(self, obs):\n",
    "        lat, lon = obs[\"gnss\"][\"latitude\"], obs[\"gnss\"][\"longitude\"]\n",
    "        x = -14418.6285 * lat + 111279.5690 * lon - 3.19252014\n",
    "        y = -109660.6210 * lat + 4.33686914 * lon + 0.367254638\n",
    "        return Location(x, y)\n",
    "    \n",
    "    def get_state(self, obs, lane_deviation, obstacle_proximity):\n",
    "        current_loc = self.get_current_location(obs)\n",
    "\n",
    "        if self.wp_index < len(self.route):\n",
    "            next_wp_loc = self.route[self.wp_index]\n",
    "            distance = current_loc.distance(next_wp_loc) / 100.0\n",
    "            vehicle_yaw = quaternion_to_yaw(obs[\"imu\"][\"orientation\"])\n",
    "            delta_x = next_wp_loc.x - current_loc.x\n",
    "            delta_y = next_wp_loc.y - current_loc.y\n",
    "            desired_yaw = np.arctan2(delta_y, delta_x)\n",
    "            angle_to_way_point = normalize_angle(desired_yaw - vehicle_yaw)\n",
    "        else:\n",
    "            distance = 0\n",
    "            angle_to_way_point = 0\n",
    "        \n",
    "        if self.previous_location is not None and self.previous_timestamp < obs[\"timestamp\"]:\n",
    "            time_elapsed = obs[\"timestamp\"] - self.previous_timestamp\n",
    "            distance_travelled = current_loc.distance(self.previous_location)\n",
    "            speed = (distance_travelled / time_elapsed if time_elapsed > 0 else 0) /20.0\n",
    "        else:\n",
    "            speed = 0\n",
    "\n",
    "        return np.array([distance, angle_to_way_point, speed, lane_deviation, obstacle_proximity], dtype=np.float32)\n",
    "    \n",
    "    def get_distance_to_waypoint(self, obs):\n",
    "        current_loc = self.get_current_location(obs)\n",
    "        if self.wp_index < len(self.route):\n",
    "            next_wp_loc = self.route[self.wp_index]\n",
    "            return current_loc.distance(next_wp_loc)\n",
    "        return 0\n",
    "    \n",
    "    def compute_reward(self, obs, lane_deviation, obstacle_proximity, steer):\n",
    "        current_distance = self.get_distance_to_waypoint(obs)\n",
    "        progress = self.previous_distance - current_distance\n",
    "        reward = progress\n",
    "\n",
    "        reward -= 0.1 * abs(lane_deviation)\n",
    "\n",
    "        if obstacle_proximity > 0.5:\n",
    "            reward -= (obstacle_proximity - 0.5) * 20\n",
    "        \n",
    "        if obs[\"collision\"] is not None:\n",
    "            reward -= 100\n",
    "\n",
    "        if obs[\"lane_invaded\"][\"violated\"]:\n",
    "            reward -= 10\n",
    "\n",
    "        speed = self.get_state(obs, lane_deviation, obstacle_proximity)[2] * 20.0\n",
    "        if speed < 5 or speed > 10:\n",
    "            reward -= 0.1\n",
    "        else:\n",
    "            reward += 0.1\n",
    "\n",
    "        steer_change = abs(steer - self.previous_steer)\n",
    "        if steer_change > 0.2:\n",
    "            reward -= steer_change * 5\n",
    "\n",
    "        return reward\n",
    "    \n",
    "    \n",
    "    def is_terminated(self, obs):\n",
    "        if self.wp_index >= len(self.route):\n",
    "            return True\n",
    "        \n",
    "        current_distance = self.get_distance_to_waypoint(obs)\n",
    "        if self.wp_index == len(self.route) - 1 and current_distance < 5.0:\n",
    "            print(\"Near final waypoint, success\")\n",
    "            return True\n",
    "        elif current_distance < 2.0:\n",
    "            self.wp_index += 1\n",
    "            if self.wp_index >= len(self.route):\n",
    "                return True\n",
    "        \n",
    "        return False\n",
    "    \n",
    "    def is_truncated(self):\n",
    "        return self.step_count >= self.max_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\WORKSTATION2\\Miniconda3\\envs\\carla_rl\\lib\\site-packages\\gymnasium\\spaces\\box.py:235: UserWarning: \u001b[33mWARN: Box low's precision lowered by casting to float32, current low.dtype=float64\u001b[0m\n",
      "  gym.logger.warn(\n",
      "c:\\Users\\WORKSTATION2\\Miniconda3\\envs\\carla_rl\\lib\\site-packages\\gymnasium\\spaces\\box.py:305: UserWarning: \u001b[33mWARN: Box high's precision lowered by casting to float32, current high.dtype=float64\u001b[0m\n",
      "  gym.logger.warn(\n",
      "c:\\Users\\WORKSTATION2\\Miniconda3\\envs\\carla_rl\\lib\\site-packages\\stable_baselines3\\common\\on_policy_algorithm.py:150: UserWarning: You are trying to run PPO on the GPU, but it is primarily intended to run on the CPU when not using a CNN policy (you are using ActorCriticPolicy which should be a MlpPolicy). See https://github.com/DLR-RM/stable-baselines3/issues/1245 for more info. You can pass `device='cpu'` or `export CUDA_VISIBLE_DEVICES=` to force using the CPU.Note: The model will train, but the GPU utilization will be poor and the training might take longer than on CPU.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 2e+03     |\n",
      "|    ep_rew_mean     | -1.44e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 13        |\n",
      "|    iterations      | 1         |\n",
      "|    time_elapsed    | 157       |\n",
      "|    total_timesteps | 2048      |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2e+03        |\n",
      "|    ep_rew_mean          | -1.94e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 12           |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 321          |\n",
      "|    total_timesteps      | 4096         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015938233 |\n",
      "|    clip_fraction        | 0.00488      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.83        |\n",
      "|    explained_variance   | -0.00185     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 5.98e+03     |\n",
      "|    n_updates            | 10           |\n",
      "|    policy_gradient_loss | -0.0027      |\n",
      "|    std                  | 0.996        |\n",
      "|    value_loss           | 1.37e+04     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2e+03       |\n",
      "|    ep_rew_mean          | -1.89e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 13          |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 445         |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004464809 |\n",
      "|    clip_fraction        | 0.0109      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.83       |\n",
      "|    explained_variance   | -0.0522     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.73e+04    |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.00231    |\n",
      "|    std                  | 0.994       |\n",
      "|    value_loss           | 3.82e+04    |\n",
      "-----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    env = CarlaEnv(port=6501)\n",
    "    check_point_callback = CheckpointCallback(save_freq=50000, save_path='./checkpoints/', name_prefix='carla_rl_model')\n",
    "\n",
    "    model = PPO(\n",
    "        \"MlpPolicy\",\n",
    "        env,\n",
    "        verbose=1,\n",
    "        n_steps=2048,\n",
    "        batch_size=64,\n",
    "        n_epochs=10,\n",
    "        gamma=0.99,\n",
    "        learning_rate=3e-4,\n",
    "        gae_lambda=0.95,\n",
    "        ent_coef=0.01\n",
    "    )\n",
    "\n",
    "    total_timesteps = 5000000\n",
    "\n",
    "    model.learn(total_timesteps=total_timesteps, callback=check_point_callback, progress_bar=False)\n",
    "\n",
    "    model.save(\"carla_rl_agent\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs, _ = env.reset()\n",
    "for _ in range(1000):\n",
    "    action, _ = model.predict(obs, deterministic=True)\n",
    "    obs, reward, terminated, truncated, info = env.step(action)\n",
    "    image = decode_image(obs[\"image\"])\n",
    "    processed_img, _, _ = process_frame(image)  # Only need the image for display\n",
    "    cv2.imshow(\"Processed Image\", processed_img)\n",
    "    print(f\"Action: {action}, Reward: {reward}, Terminated: {terminated}, Truncated: {truncated}\")\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "    if terminated or truncated:\n",
    "        obs, _ = env.reset()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.6.0+cu124\n",
      "CUDA available: True\n",
      "GPU: NVIDIA RTX 5000 Ada Generation\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(\"PyTorch version:\", torch.__version__)\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "if torch.cuda.is_available():\n",
    "    print(\"GPU:\", torch.cuda.get_device_name(0))\n",
    "else:\n",
    "    print(\"CUDA not available\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.11.0) :-1: error: (-5:Bad argument) in function 'imshow'\n> Overload resolution failed:\n>  - mat is not a numerical tuple\n>  - Expected Ptr<cv::cuda::GpuMat> for argument 'mat'\n>  - Expected Ptr<cv::UMat> for argument 'mat'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 51\u001b[0m\n\u001b[0;32m     41\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m     43\u001b[0m \u001b[38;5;66;03m# print(f\"[Step {step}] GNSS: {gnss} | Time: {timestamp} | Collision: {collision} | imu: {imu} | lane: {lane_invaded}\")\u001b[39;00m\n\u001b[0;32m     44\u001b[0m \u001b[38;5;66;03m# # print(f\"lane: {lane_invaded}\")\u001b[39;00m\n\u001b[0;32m     45\u001b[0m \u001b[38;5;66;03m# if lane_invaded['violated'] == True:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     49\u001b[0m \n\u001b[0;32m     50\u001b[0m \u001b[38;5;66;03m# Optional: show image\u001b[39;00m\n\u001b[1;32m---> 51\u001b[0m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimshow\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mCamera\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprocsses_image\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;66;03m# cv2.imshow(\"Camera1\", image)\u001b[39;00m\n\u001b[0;32m     53\u001b[0m cv2\u001b[38;5;241m.\u001b[39mwaitKey(\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\WORKSTATION2\\Miniconda3\\envs\\carla_rl\\lib\\site-packages\\ultralytics\\utils\\patches.py:77\u001b[0m, in \u001b[0;36mimshow\u001b[1;34m(winname, mat)\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mimshow\u001b[39m(winname: \u001b[38;5;28mstr\u001b[39m, mat: np\u001b[38;5;241m.\u001b[39mndarray):\n\u001b[0;32m     60\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;124;03m    Display an image in the specified window.\u001b[39;00m\n\u001b[0;32m     62\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[38;5;124;03m        >>> imshow(\"Example Window\", img)  # Display the image\u001b[39;00m\n\u001b[0;32m     76\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 77\u001b[0m     \u001b[43m_imshow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwinname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43municode_escape\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmat\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.11.0) :-1: error: (-5:Bad argument) in function 'imshow'\n> Overload resolution failed:\n>  - mat is not a numerical tuple\n>  - Expected Ptr<cv::cuda::GpuMat> for argument 'mat'\n>  - Expected Ptr<cv::UMat> for argument 'mat'\n"
     ]
    }
   ],
   "source": [
    "context = zmq.Context()\n",
    "socket = context.socket(zmq.REQ)\n",
    "socket.connect(\"tcp://localhost:6501\")\n",
    "\n",
    "def send_action(steer: float, throttle: float):\n",
    "    action = {\n",
    "        \"action\": [steer, throttle]\n",
    "    }\n",
    "    socket.send(pickle.dumps(action))  # Serialize & send\n",
    "    response = socket.recv()           # Receive serialized reply\n",
    "    data = pickle.loads(response)      # Deserialize\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "# ==== Decode image from bytes ====\n",
    "def decode_image(image_bytes):\n",
    "    np_arr = np.frombuffer(image_bytes, dtype=np.uint8)\n",
    "    img = cv2.imdecode(np_arr, cv2.IMREAD_COLOR)\n",
    "    return img\n",
    "\n",
    "# ==== Main loop ====\n",
    "for step in range(200):\n",
    "    steer = 0\n",
    "    throttle = -1\n",
    "    obs = send_action(steer, throttle)\n",
    "\n",
    "    # Extract observation\n",
    "    # try:\n",
    "    image = decode_image(obs[\"image\"])\n",
    "    gnss = obs[\"gnss\"]\n",
    "    collision = obs[\"collision\"]\n",
    "    imu = obs[\"imu\"]\n",
    "    timestamp = obs[\"timestamp\"]\n",
    "    lane_invaded = obs[\"lane_invaded\"]\n",
    "    \n",
    "    procsses_image = process_frame(image)\n",
    "    \n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        quit = True\n",
    "        break\n",
    "    \n",
    "    # print(f\"[Step {step}] GNSS: {gnss} | Time: {timestamp} | Collision: {collision} | imu: {imu} | lane: {lane_invaded}\")\n",
    "    # # print(f\"lane: {lane_invaded}\")\n",
    "    # if lane_invaded['violated'] == True:\n",
    "    #     print(lane_invaded[\"last_event\"])\n",
    "    #     print(lane_invaded)\n",
    "        # cv2.imshow(\"Invasion\", image)\n",
    "\n",
    "    # Optional: show image\n",
    "    cv2.imshow(\"Camera\", procsses_image)\n",
    "    # cv2.imshow(\"Camera1\", image)\n",
    "    cv2.waitKey(1)\n",
    "\n",
    "    # except Exception as e:\n",
    "    #     print(lane_invaded[\"last_event\"])\n",
    "    #     print(lane_invaded)\n",
    "    #     print(e)\n",
    "    #     # print(f\"[ERROR] Failed to process observation: {e}\")\n",
    "    #     # print(f\"[DEBUG] Image shape before processing: {image.shape}\")\n",
    "    #     pass\n",
    "    #     # break\n",
    "\n",
    "    # time.sleep(0.05) \n",
    "cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_command = {\"command\": \"reset\"}\n",
    "socket.send(pickle.dumps(reset_command))\n",
    "_ = socket.recv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import zmq\n",
    "import pickle\n",
    "import numpy as np\n",
    "context = zmq.Context()\n",
    "socket = context.socket(zmq.REQ)\n",
    "socket.connect(\"tcp://localhost:6501\")\n",
    "\n",
    "def send_action(steer: float, throttle: float):\n",
    "    action = {\"action\": [steer, throttle]}\n",
    "    socket.send(pickle.dumps(action))\n",
    "    response = socket.recv()\n",
    "    data = pickle.loads(response)\n",
    "    return data\n",
    "\n",
    "def decode_image(image_bytes):\n",
    "    np_arr = np.frombuffer(image_bytes, dtype=np.uint8)\n",
    "    img = cv2.imdecode(np_arr, cv2.IMREAD_COLOR)\n",
    "    return img\n",
    "\n",
    "# Main loop\n",
    "for step in range(200):\n",
    "    steer = 0.01\n",
    "    throttle = 0.0\n",
    "    obs = send_action(steer, throttle)\n",
    "\n",
    "    # Extract observation\n",
    "    image = decode_image(obs[\"image\"])\n",
    "    gnss = obs[\"gnss\"]\n",
    "    collision = obs[\"collision\"]\n",
    "    imu = obs[\"imu\"]\n",
    "    timestamp = obs[\"timestamp\"]\n",
    "    lane_invaded = obs[\"lane_invaded\"]\n",
    "    \n",
    "    # Unpack the tuple from process_frame\n",
    "    processed_image, lane_deviation, obstacle_proximity = process_frame(image)\n",
    "    \n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        quit = True\n",
    "        break\n",
    "\n",
    "    height = 400  # Adjust the height as needed\n",
    "    processed_image_resized = cv2.resize(processed_image, (height, height))\n",
    "    lane_deviation_resized = cv2.resize(lane_deviation, (height, height))\n",
    "    obstacle_proximity_resized = cv2.resize(obstacle_proximity, (height, height))\n",
    "\n",
    "    # Ensure images are in the correct type (uint8) before converting\n",
    "    if lane_deviation_resized.dtype != np.uint8:\n",
    "        lane_deviation_resized = np.uint8(lane_deviation_resized)\n",
    "\n",
    "    if obstacle_proximity_resized.dtype != np.uint8:\n",
    "        obstacle_proximity_resized = np.uint8(obstacle_proximity_resized)\n",
    "\n",
    "    # Convert single-channel images to 3-channel images (RGB)\n",
    "    if len(lane_deviation_resized.shape) == 2:  # If grayscale\n",
    "        lane_deviation_resized = cv2.cvtColor(lane_deviation_resized, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "    if len(obstacle_proximity_resized.shape) == 2:  # If grayscale\n",
    "        obstacle_proximity_resized = cv2.cvtColor(obstacle_proximity_resized, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "    # Concatenate images horizontally\n",
    "    combined_image = np.hstack((processed_image_resized, lane_deviation_resized, obstacle_proximity_resized))\n",
    "\n",
    "    # Show the combined image\n",
    "    cv2.imshow(\"All Images\", combined_image)\n",
    "    \n",
    "    # Optional: show image\n",
    "    # cv2.imshow(\"Camera\", processed_image) \n",
    "    # cv2.imshow(\"Camera\", lane_deviation)  # Use processed_image, not the tuple\n",
    "    # cv2.imshow(\"Camera\", obstacle_proximity)  # Use processed_image, not the tuple\n",
    "     # Use processed_image, not the tuple\n",
    "    cv2.waitKey(1)\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "carla_rl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
