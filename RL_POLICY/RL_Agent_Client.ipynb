{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import zmq\n",
    "import pickle\n",
    "import numpy as np\n",
    "import gymnasium as gym\n",
    "from gymnasium import spaces\n",
    "from stable_baselines3 import PPO\n",
    "from process_frame import process_frame\n",
    "from stable_baselines3.common.callbacks import CheckpointCallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Location:\n",
    "    def __init__(self, x, y, z=0.0):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.z = z\n",
    "\n",
    "    def distance(self, other):\n",
    "        return np.sqrt((self.x - other.x)**2 + (self.y - other.y)**2 + (self.z - other.z)**2)\n",
    "\n",
    "def quaternion_to_yaw(q):\n",
    "    w, x, y, z = q[\"w\"], q[\"x\"], q[\"y\"], q[\"z\"]\n",
    "    siny_cosp = 2 * (w * z + x * y)\n",
    "    cosy_cosp = 1 - 2 * (y**2 + z**2)\n",
    "    yaw = np.arctan2(siny_cosp, cosy_cosp)\n",
    "    return yaw \n",
    "\n",
    "def normalize_angle(angle):\n",
    "    while angle > np.pi:\n",
    "        angle -= 2 * np.pi\n",
    "    while angle < -np.pi:\n",
    "        angle += 2 * np.pi\n",
    "    return angle\n",
    "\n",
    "def decode_image(image_bytes):\n",
    "    np_arr = np.frombuffer(image_bytes, dtype=np.uint8)\n",
    "    img = cv2.imdecode(np_arr, cv2.IMREAD_COLOR)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CarlaEnv(gym.Env):\n",
    "    def __init__(self, port=6501):\n",
    "        super(CarlaEnv, self).__init__()\n",
    "        self.port = port\n",
    "        self.context = zmq.Context()\n",
    "        self.socket = self.context.socket(zmq.REQ)\n",
    "        self.socket.connect(f\"tcp://localhost:{self.port}\")\n",
    "\n",
    "        self.action_space = spaces.Box(low=-1, high=1, shape=(2,), dtype=np.float32)\n",
    "                                                 # [dist, angle, speed, lane_dev, obs_prox]\n",
    "        self.observation_space = spaces.Box(low=np.array([-np.inf, -np.pi, 0, -1, 0]),\n",
    "                                            high=np.array([np.inf, np.pi, np.inf, 1, 1]),\n",
    "                                            dtype=np.float32)\n",
    "        \n",
    "        self.route = None\n",
    "        self.wp_index = 0\n",
    "\n",
    "        self.previous_location = None\n",
    "        self.previous_timestamp = None\n",
    "        self.previous_distance = None\n",
    "\n",
    "        self.max_steps = 2000\n",
    "        self.step_count = 0\n",
    "\n",
    "\n",
    "    def reset(self, seed = None, options = None):\n",
    "        self.socket.send(pickle.dumps({\"command\": \"reset\"}))\n",
    "        \n",
    "        response = pickle.loads(self.socket.recv())\n",
    "        # print(response)\n",
    "        if response[\"status\"] != \"reset done\":\n",
    "            raise RuntimeError(f\"Server reset failed check port cur port {self.port}\")\n",
    "        \n",
    "        obs = response[\"observation\"] \n",
    "        self.route = [Location(x, y) for [x, y] in response[\"route\"]]\n",
    "        self.wp_index = 0\n",
    "\n",
    "        image = decode_image(obs[\"image\"])\n",
    "        _, lane_deviation, obstacle_proximity = process_frame(image)\n",
    "        state = self.get_state(obs, lane_deviation, obstacle_proximity)\n",
    "\n",
    "        self.previous_location = self.get_current_location(obs)\n",
    "        self.previous_timestamp = obs[\"timestamp\"]\n",
    "        self.previous_distance = self.get_distance_to_waypoint(obs)\n",
    "        self.previous_steer = 0\n",
    "        self.step_count=0\n",
    "\n",
    "        return state, {}\n",
    "    \n",
    "    def step(self, action):\n",
    "        self.socket.send(pickle.dumps({\"action\": action.tolist()}))\n",
    "        obs = pickle.loads(self.socket.recv())\n",
    "\n",
    "        image = decode_image(obs[\"image\"])\n",
    "        processed_image, lane_deviation, obstacle_proximity = process_frame(image)\n",
    "        state = self.get_state(obs, lane_deviation, obstacle_proximity)\n",
    "\n",
    "        reward = self.compute_reward(obs, lane_deviation, obstacle_proximity, action[0])\n",
    "\n",
    "        if obs[\"collision\"] is not None:\n",
    "            print(\"Collision detected, respawning...\")\n",
    "            obs, _ = self.reset()\n",
    "            state = self.get_state(obs, lane_deviation, obstacle_proximity)\n",
    "            reward -= 100\n",
    "\n",
    "        terminated = self.is_terminated(obs)\n",
    "        truncated = self.is_truncated()\n",
    "\n",
    "        self.step_count += 1\n",
    "\n",
    "        self.previous_location = self.get_current_location(obs)\n",
    "        self.previous_timestamp = obs[\"timestamp\"]\n",
    "        self.previous_distance = self.get_distance_to_waypoint(obs)\n",
    "        self.previous_steer = action[0]\n",
    "\n",
    "        return state, reward, terminated, truncated, {}\n",
    "    \n",
    "    def get_current_location(self, obs):\n",
    "        lat, lon = obs[\"gnss\"][\"latitude\"], obs[\"gnss\"][\"longitude\"]\n",
    "        x = -14418.6285 * lat + 111279.5690 * lon - 3.19252014\n",
    "        y = -109660.6210 * lat + 4.33686914 * lon + 0.367254638\n",
    "        return Location(x, y)\n",
    "    \n",
    "    def get_state(self, obs, lane_deviation, obstacle_proximity):\n",
    "        current_loc = self.get_current_location(obs)\n",
    "\n",
    "        if self.wp_index < len(self.route):\n",
    "            next_wp_loc = self.route[self.wp_index]\n",
    "            distance = current_loc.distance(next_wp_loc) / 100.0\n",
    "            vehicle_yaw = quaternion_to_yaw(obs[\"imu\"][\"orientation\"])\n",
    "            delta_x = next_wp_loc.x - current_loc.x\n",
    "            delta_y = next_wp_loc.y - current_loc.y\n",
    "            desired_yaw = np.arctan2(delta_y, delta_x)\n",
    "            angle_to_way_point = normalize_angle(desired_yaw - vehicle_yaw)\n",
    "        else:\n",
    "            distance = 0\n",
    "            angle_to_way_point = 0\n",
    "        \n",
    "        if self.previous_location is not None and self.previous_timestamp < obs[\"timestamp\"]:\n",
    "            time_elapsed = obs[\"timestamp\"] - self.previous_timestamp\n",
    "            distance_travelled = current_loc.distance(self.previous_location)\n",
    "            speed = (distance_travelled / time_elapsed if time_elapsed > 0 else 0) /20.0\n",
    "        else:\n",
    "            speed = 0\n",
    "\n",
    "        return np.array([distance, angle_to_way_point, speed, lane_deviation, obstacle_proximity], dtype=np.float32)\n",
    "    \n",
    "    def get_distance_to_waypoint(self, obs):\n",
    "        current_loc = self.get_current_location(obs)\n",
    "        if self.wp_index < len(self.route):\n",
    "            next_wp_loc = self.route[self.wp_index]\n",
    "            return current_loc.distance(next_wp_loc)\n",
    "        return 0\n",
    "    \n",
    "    def compute_reward(self, obs, lane_deviation, obstacle_proximity, steer):\n",
    "        current_distance = self.get_distance_to_waypoint(obs)\n",
    "        progress = self.previous_distance - current_distance\n",
    "        reward = progress\n",
    "\n",
    "        reward -= 0.1 * abs(lane_deviation)\n",
    "\n",
    "        if obstacle_proximity > 0.5:\n",
    "            reward -= (obstacle_proximity - 0.5) * 20\n",
    "        \n",
    "        if obs[\"collision\"] is not None:\n",
    "            reward -= 100\n",
    "\n",
    "        if obs[\"lane_invaded\"][\"violated\"]:\n",
    "            reward -= 10\n",
    "\n",
    "        speed = self.get_state(obs, lane_deviation, obstacle_proximity)[2] * 20.0\n",
    "        if speed < 5 or speed > 10:\n",
    "            reward -= 0.1\n",
    "        else:\n",
    "            reward += 0.1\n",
    "\n",
    "        steer_change = abs(steer - self.previous_steer)\n",
    "        if steer_change > 0.2:\n",
    "            reward -= steer_change * 5\n",
    "\n",
    "        return reward\n",
    "    \n",
    "    \n",
    "    def is_terminated(self, obs):\n",
    "        if self.wp_index >= len(self.route):\n",
    "            return True\n",
    "        \n",
    "        current_distance = self.get_distance_to_waypoint(obs)\n",
    "        if self.wp_index == len(self.route) - 1 and current_distance < 5.0:\n",
    "            print(\"Near final waypoint, success\")\n",
    "            return True\n",
    "        elif current_distance < 2.0:\n",
    "            self.wp_index += 1\n",
    "            if self.wp_index >= len(self.route):\n",
    "                return True\n",
    "        \n",
    "        return False\n",
    "    \n",
    "    def is_truncated(self):\n",
    "        return self.step_count >= self.max_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Collision detected, respawning...\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 20\u001b[0m\n\u001b[0;32m      5\u001b[0m model \u001b[38;5;241m=\u001b[39m PPO(\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMlpPolicy\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      7\u001b[0m     env,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     15\u001b[0m     ent_coef\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.01\u001b[39m\n\u001b[0;32m     16\u001b[0m )\n\u001b[0;32m     18\u001b[0m total_timesteps \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5000000\u001b[39m\n\u001b[1;32m---> 20\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtotal_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtotal_timesteps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcheck_point_callback\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     22\u001b[0m model\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcarla_rl_agent\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\WORKSTATION2\\Miniconda3\\envs\\carla_rl\\lib\\site-packages\\stable_baselines3\\ppo\\ppo.py:311\u001b[0m, in \u001b[0;36mPPO.learn\u001b[1;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[0;32m    302\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mlearn\u001b[39m(\n\u001b[0;32m    303\u001b[0m     \u001b[38;5;28mself\u001b[39m: SelfPPO,\n\u001b[0;32m    304\u001b[0m     total_timesteps: \u001b[38;5;28mint\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    309\u001b[0m     progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    310\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m SelfPPO:\n\u001b[1;32m--> 311\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    312\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtotal_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtotal_timesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    313\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    314\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlog_interval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlog_interval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    315\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtb_log_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtb_log_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    316\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreset_num_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset_num_timesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    317\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    318\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\WORKSTATION2\\Miniconda3\\envs\\carla_rl\\lib\\site-packages\\stable_baselines3\\common\\on_policy_algorithm.py:324\u001b[0m, in \u001b[0;36mOnPolicyAlgorithm.learn\u001b[1;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[0;32m    321\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    323\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_timesteps \u001b[38;5;241m<\u001b[39m total_timesteps:\n\u001b[1;32m--> 324\u001b[0m     continue_training \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollect_rollouts\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrollout_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_rollout_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_steps\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m continue_training:\n\u001b[0;32m    327\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\WORKSTATION2\\Miniconda3\\envs\\carla_rl\\lib\\site-packages\\stable_baselines3\\common\\on_policy_algorithm.py:218\u001b[0m, in \u001b[0;36mOnPolicyAlgorithm.collect_rollouts\u001b[1;34m(self, env, callback, rollout_buffer, n_rollout_steps)\u001b[0m\n\u001b[0;32m    213\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    214\u001b[0m         \u001b[38;5;66;03m# Otherwise, clip the actions to avoid out of bound error\u001b[39;00m\n\u001b[0;32m    215\u001b[0m         \u001b[38;5;66;03m# as we are sampling from an unbounded Gaussian distribution\u001b[39;00m\n\u001b[0;32m    216\u001b[0m         clipped_actions \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mclip(actions, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maction_space\u001b[38;5;241m.\u001b[39mlow, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maction_space\u001b[38;5;241m.\u001b[39mhigh)\n\u001b[1;32m--> 218\u001b[0m new_obs, rewards, dones, infos \u001b[38;5;241m=\u001b[39m \u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclipped_actions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    220\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_timesteps \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39mnum_envs\n\u001b[0;32m    222\u001b[0m \u001b[38;5;66;03m# Give access to local variables\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\WORKSTATION2\\Miniconda3\\envs\\carla_rl\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\base_vec_env.py:222\u001b[0m, in \u001b[0;36mVecEnv.step\u001b[1;34m(self, actions)\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    216\u001b[0m \u001b[38;5;124;03mStep the environments with the given action\u001b[39;00m\n\u001b[0;32m    217\u001b[0m \n\u001b[0;32m    218\u001b[0m \u001b[38;5;124;03m:param actions: the action\u001b[39;00m\n\u001b[0;32m    219\u001b[0m \u001b[38;5;124;03m:return: observation, reward, done, information\u001b[39;00m\n\u001b[0;32m    220\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    221\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstep_async(actions)\n\u001b[1;32m--> 222\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep_wait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\WORKSTATION2\\Miniconda3\\envs\\carla_rl\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\dummy_vec_env.py:59\u001b[0m, in \u001b[0;36mDummyVecEnv.step_wait\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mstep_wait\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m VecEnvStepReturn:\n\u001b[0;32m     57\u001b[0m     \u001b[38;5;66;03m# Avoid circular imports\u001b[39;00m\n\u001b[0;32m     58\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m env_idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_envs):\n\u001b[1;32m---> 59\u001b[0m         obs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuf_rews[env_idx], terminated, truncated, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuf_infos[env_idx] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menvs\u001b[49m\u001b[43m[\u001b[49m\u001b[43menv_idx\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[assignment]\u001b[39;49;00m\n\u001b[0;32m     60\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mactions\u001b[49m\u001b[43m[\u001b[49m\u001b[43menv_idx\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m     61\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     62\u001b[0m         \u001b[38;5;66;03m# convert to SB3 VecEnv api\u001b[39;00m\n\u001b[0;32m     63\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuf_dones[env_idx] \u001b[38;5;241m=\u001b[39m terminated \u001b[38;5;129;01mor\u001b[39;00m truncated\n",
      "File \u001b[1;32mc:\\Users\\WORKSTATION2\\Miniconda3\\envs\\carla_rl\\lib\\site-packages\\stable_baselines3\\common\\monitor.py:94\u001b[0m, in \u001b[0;36mMonitor.step\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m     92\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mneeds_reset:\n\u001b[0;32m     93\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTried to step environment that needs reset\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 94\u001b[0m observation, reward, terminated, truncated, info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     95\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrewards\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mfloat\u001b[39m(reward))\n\u001b[0;32m     96\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m terminated \u001b[38;5;129;01mor\u001b[39;00m truncated:\n",
      "Cell \u001b[1;32mIn[7], line 63\u001b[0m, in \u001b[0;36mCarlaEnv.step\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m     61\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCollision detected, respawning...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     62\u001b[0m     obs, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreset()\n\u001b[1;32m---> 63\u001b[0m     state \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_state\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlane_deviation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobstacle_proximity\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     64\u001b[0m     reward \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m100\u001b[39m\n\u001b[0;32m     66\u001b[0m terminated \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_terminated(obs)\n",
      "Cell \u001b[1;32mIn[7], line 85\u001b[0m, in \u001b[0;36mCarlaEnv.get_state\u001b[1;34m(self, obs, lane_deviation, obstacle_proximity)\u001b[0m\n\u001b[0;32m     84\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mget_state\u001b[39m(\u001b[38;5;28mself\u001b[39m, obs, lane_deviation, obstacle_proximity):\n\u001b[1;32m---> 85\u001b[0m     current_loc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_current_location\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     87\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwp_index \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mroute):\n\u001b[0;32m     88\u001b[0m         next_wp_loc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mroute[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwp_index]\n",
      "Cell \u001b[1;32mIn[7], line 79\u001b[0m, in \u001b[0;36mCarlaEnv.get_current_location\u001b[1;34m(self, obs)\u001b[0m\n\u001b[0;32m     78\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mget_current_location\u001b[39m(\u001b[38;5;28mself\u001b[39m, obs):\n\u001b[1;32m---> 79\u001b[0m     lat, lon \u001b[38;5;241m=\u001b[39m \u001b[43mobs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgnss\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlatitude\u001b[39m\u001b[38;5;124m\"\u001b[39m], obs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgnss\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlongitude\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m     80\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m14418.6285\u001b[39m \u001b[38;5;241m*\u001b[39m lat \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m111279.5690\u001b[39m \u001b[38;5;241m*\u001b[39m lon \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m3.19252014\u001b[39m\n\u001b[0;32m     81\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m109660.6210\u001b[39m \u001b[38;5;241m*\u001b[39m lat \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m4.33686914\u001b[39m \u001b[38;5;241m*\u001b[39m lon \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m0.367254638\u001b[39m\n",
      "\u001b[1;31mIndexError\u001b[0m: only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    env = CarlaEnv(port=6501)\n",
    "    check_point_callback = CheckpointCallback(save_freq=50000, save_path='./checkpoints/', name_prefix='carla_rl_model')\n",
    "\n",
    "    model = PPO(\n",
    "        \"MlpPolicy\",\n",
    "        env,\n",
    "        verbose=1,\n",
    "        n_steps=2048,\n",
    "        batch_size=64,\n",
    "        n_epochs=10,\n",
    "        gamma=0.99,\n",
    "        learning_rate=3e-4,\n",
    "        gae_lambda=0.95,\n",
    "        ent_coef=0.01\n",
    "    )\n",
    "\n",
    "    total_timesteps = 5000000\n",
    "\n",
    "    model.learn(total_timesteps=total_timesteps, callback=check_point_callback, progress_bar=False)\n",
    "\n",
    "    model.save(\"carla_rl_agent\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs, _ = env.reset()\n",
    "for _ in range(1000):\n",
    "    action, _ = model.predict(obs, deterministic=True)\n",
    "    obs, reward, terminated, truncated, info = env.step(action)\n",
    "    image = decode_image(obs[\"image\"])\n",
    "    processed_img, _, _ = process_frame(image)  # Only need the image for display\n",
    "    cv2.imshow(\"Processed Image\", processed_img)\n",
    "    print(f\"Action: {action}, Reward: {reward}, Terminated: {terminated}, Truncated: {truncated}\")\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "    if terminated or truncated:\n",
    "        obs, _ = env.reset()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.6.0+cpu\n",
      "CUDA available: False\n",
      "No CUDA device detected\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA version: {torch.version.cuda}\")\n",
    "    print(f\"Current device: {torch.cuda.current_device()}\")\n",
    "    print(f\"Device name: {torch.cuda.get_device_name(0)}\")\n",
    "else:\n",
    "    print(\"No CUDA device detected\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.11.0) :-1: error: (-5:Bad argument) in function 'imshow'\n> Overload resolution failed:\n>  - mat is not a numerical tuple\n>  - Expected Ptr<cv::cuda::GpuMat> for argument 'mat'\n>  - Expected Ptr<cv::UMat> for argument 'mat'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 51\u001b[0m\n\u001b[0;32m     41\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m     43\u001b[0m \u001b[38;5;66;03m# print(f\"[Step {step}] GNSS: {gnss} | Time: {timestamp} | Collision: {collision} | imu: {imu} | lane: {lane_invaded}\")\u001b[39;00m\n\u001b[0;32m     44\u001b[0m \u001b[38;5;66;03m# # print(f\"lane: {lane_invaded}\")\u001b[39;00m\n\u001b[0;32m     45\u001b[0m \u001b[38;5;66;03m# if lane_invaded['violated'] == True:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     49\u001b[0m \n\u001b[0;32m     50\u001b[0m \u001b[38;5;66;03m# Optional: show image\u001b[39;00m\n\u001b[1;32m---> 51\u001b[0m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimshow\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mCamera\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprocsses_image\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;66;03m# cv2.imshow(\"Camera1\", image)\u001b[39;00m\n\u001b[0;32m     53\u001b[0m cv2\u001b[38;5;241m.\u001b[39mwaitKey(\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\WORKSTATION2\\Miniconda3\\envs\\carla_rl\\lib\\site-packages\\ultralytics\\utils\\patches.py:77\u001b[0m, in \u001b[0;36mimshow\u001b[1;34m(winname, mat)\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mimshow\u001b[39m(winname: \u001b[38;5;28mstr\u001b[39m, mat: np\u001b[38;5;241m.\u001b[39mndarray):\n\u001b[0;32m     60\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;124;03m    Display an image in the specified window.\u001b[39;00m\n\u001b[0;32m     62\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[38;5;124;03m        >>> imshow(\"Example Window\", img)  # Display the image\u001b[39;00m\n\u001b[0;32m     76\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 77\u001b[0m     \u001b[43m_imshow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwinname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43municode_escape\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmat\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.11.0) :-1: error: (-5:Bad argument) in function 'imshow'\n> Overload resolution failed:\n>  - mat is not a numerical tuple\n>  - Expected Ptr<cv::cuda::GpuMat> for argument 'mat'\n>  - Expected Ptr<cv::UMat> for argument 'mat'\n"
     ]
    }
   ],
   "source": [
    "context = zmq.Context()\n",
    "socket = context.socket(zmq.REQ)\n",
    "socket.connect(\"tcp://localhost:6501\")\n",
    "\n",
    "def send_action(steer: float, throttle: float):\n",
    "    action = {\n",
    "        \"action\": [steer, throttle]\n",
    "    }\n",
    "    socket.send(pickle.dumps(action))  # Serialize & send\n",
    "    response = socket.recv()           # Receive serialized reply\n",
    "    data = pickle.loads(response)      # Deserialize\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "# ==== Decode image from bytes ====\n",
    "def decode_image(image_bytes):\n",
    "    np_arr = np.frombuffer(image_bytes, dtype=np.uint8)\n",
    "    img = cv2.imdecode(np_arr, cv2.IMREAD_COLOR)\n",
    "    return img\n",
    "\n",
    "# ==== Main loop ====\n",
    "for step in range(200):\n",
    "    steer = 0\n",
    "    throttle = -1\n",
    "    obs = send_action(steer, throttle)\n",
    "\n",
    "    # Extract observation\n",
    "    # try:\n",
    "    image = decode_image(obs[\"image\"])\n",
    "    gnss = obs[\"gnss\"]\n",
    "    collision = obs[\"collision\"]\n",
    "    imu = obs[\"imu\"]\n",
    "    timestamp = obs[\"timestamp\"]\n",
    "    lane_invaded = obs[\"lane_invaded\"]\n",
    "    \n",
    "    procsses_image = process_frame(image)\n",
    "    \n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        quit = True\n",
    "        break\n",
    "    \n",
    "    # print(f\"[Step {step}] GNSS: {gnss} | Time: {timestamp} | Collision: {collision} | imu: {imu} | lane: {lane_invaded}\")\n",
    "    # # print(f\"lane: {lane_invaded}\")\n",
    "    # if lane_invaded['violated'] == True:\n",
    "    #     print(lane_invaded[\"last_event\"])\n",
    "    #     print(lane_invaded)\n",
    "        # cv2.imshow(\"Invasion\", image)\n",
    "\n",
    "    # Optional: show image\n",
    "    cv2.imshow(\"Camera\", procsses_image)\n",
    "    # cv2.imshow(\"Camera1\", image)\n",
    "    cv2.waitKey(1)\n",
    "\n",
    "    # except Exception as e:\n",
    "    #     print(lane_invaded[\"last_event\"])\n",
    "    #     print(lane_invaded)\n",
    "    #     print(e)\n",
    "    #     # print(f\"[ERROR] Failed to process observation: {e}\")\n",
    "    #     # print(f\"[DEBUG] Image shape before processing: {image.shape}\")\n",
    "    #     pass\n",
    "    #     # break\n",
    "\n",
    "    # time.sleep(0.05) \n",
    "cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_command = {\"command\": \"reset\"}\n",
    "socket.send(pickle.dumps(reset_command))\n",
    "_ = socket.recv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import zmq\n",
    "import pickle\n",
    "import numpy as np\n",
    "context = zmq.Context()\n",
    "socket = context.socket(zmq.REQ)\n",
    "socket.connect(\"tcp://localhost:6501\")\n",
    "\n",
    "def send_action(steer: float, throttle: float):\n",
    "    action = {\"action\": [steer, throttle]}\n",
    "    socket.send(pickle.dumps(action))\n",
    "    response = socket.recv()\n",
    "    data = pickle.loads(response)\n",
    "    return data\n",
    "\n",
    "def decode_image(image_bytes):\n",
    "    np_arr = np.frombuffer(image_bytes, dtype=np.uint8)\n",
    "    img = cv2.imdecode(np_arr, cv2.IMREAD_COLOR)\n",
    "    return img\n",
    "\n",
    "# Main loop\n",
    "for step in range(200):\n",
    "    steer = 0.01\n",
    "    throttle = 0.0\n",
    "    obs = send_action(steer, throttle)\n",
    "\n",
    "    # Extract observation\n",
    "    image = decode_image(obs[\"image\"])\n",
    "    gnss = obs[\"gnss\"]\n",
    "    collision = obs[\"collision\"]\n",
    "    imu = obs[\"imu\"]\n",
    "    timestamp = obs[\"timestamp\"]\n",
    "    lane_invaded = obs[\"lane_invaded\"]\n",
    "    \n",
    "    # Unpack the tuple from process_frame\n",
    "    processed_image, lane_deviation, obstacle_proximity = process_frame(image)\n",
    "    \n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        quit = True\n",
    "        break\n",
    "\n",
    "    height = 400  # Adjust the height as needed\n",
    "    processed_image_resized = cv2.resize(processed_image, (height, height))\n",
    "    lane_deviation_resized = cv2.resize(lane_deviation, (height, height))\n",
    "    obstacle_proximity_resized = cv2.resize(obstacle_proximity, (height, height))\n",
    "\n",
    "    # Ensure images are in the correct type (uint8) before converting\n",
    "    if lane_deviation_resized.dtype != np.uint8:\n",
    "        lane_deviation_resized = np.uint8(lane_deviation_resized)\n",
    "\n",
    "    if obstacle_proximity_resized.dtype != np.uint8:\n",
    "        obstacle_proximity_resized = np.uint8(obstacle_proximity_resized)\n",
    "\n",
    "    # Convert single-channel images to 3-channel images (RGB)\n",
    "    if len(lane_deviation_resized.shape) == 2:  # If grayscale\n",
    "        lane_deviation_resized = cv2.cvtColor(lane_deviation_resized, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "    if len(obstacle_proximity_resized.shape) == 2:  # If grayscale\n",
    "        obstacle_proximity_resized = cv2.cvtColor(obstacle_proximity_resized, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "    # Concatenate images horizontally\n",
    "    combined_image = np.hstack((processed_image_resized, lane_deviation_resized, obstacle_proximity_resized))\n",
    "\n",
    "    # Show the combined image\n",
    "    cv2.imshow(\"All Images\", combined_image)\n",
    "    \n",
    "    # Optional: show image\n",
    "    # cv2.imshow(\"Camera\", processed_image) \n",
    "    # cv2.imshow(\"Camera\", lane_deviation)  # Use processed_image, not the tuple\n",
    "    # cv2.imshow(\"Camera\", obstacle_proximity)  # Use processed_image, not the tuple\n",
    "     # Use processed_image, not the tuple\n",
    "    cv2.waitKey(1)\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "carla_rl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
