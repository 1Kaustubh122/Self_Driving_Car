{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\WORKSTATION2\\Miniconda3\\envs\\carla_rl\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\WORKSTATION2\\Miniconda3\\envs\\carla_rl\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import zmq\n",
    "import pickle\n",
    "import numpy as np\n",
    "import gymnasium as gym\n",
    "from gymnasium import spaces\n",
    "from stable_baselines3 import PPO\n",
    "from process_frame import process_frame\n",
    "from stable_baselines3.common.callbacks import CheckpointCallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Location:\n",
    "    def __init__(self, x, y, z=0.0):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.z = z\n",
    "\n",
    "    def distance(self, other):\n",
    "        return np.sqrt((self.x - other.x)**2 + (self.y - other.y)**2 + (self.z - other.z)**2)\n",
    "\n",
    "def quaternion_to_yaw(q):\n",
    "    w, x, y, z = q[\"w\"], q[\"x\"], q[\"y\"], q[\"z\"]\n",
    "    siny_cosp = 2 * (w * z + x * y)\n",
    "    cosy_cosp = 1 - 2 * (y**2 + z**2)\n",
    "    yaw = np.arctan2(siny_cosp, cosy_cosp)\n",
    "    return yaw \n",
    "\n",
    "def normalize_angle(angle):\n",
    "    while angle > np.pi:\n",
    "        angle -= 2 * np.pi\n",
    "    while angle < -np.pi:\n",
    "        angle += 2 * np.pi\n",
    "    return angle\n",
    "\n",
    "def decode_image(image_bytes):\n",
    "    np_arr = np.frombuffer(image_bytes, dtype=np.uint8)\n",
    "    img = cv2.imdecode(np_arr, cv2.IMREAD_COLOR)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CarlaEnv(gym.Env):\n",
    "    def __init__(self, port=6501):\n",
    "        super(CarlaEnv, self).__init__()\n",
    "        self.port = port\n",
    "        self.context = zmq.Context()\n",
    "        self.socket = self.context.socket(zmq.REQ)\n",
    "        self.socket.connect(f\"tcp://localhost:{self.port}\")\n",
    "\n",
    "        self.action_space = spaces.Box(low=-1, high=1, shape=(2,), dtype=np.float32)\n",
    "                                                 # [dist, angle, speed, lane_dev, obs_prox]\n",
    "        self.observation_space = spaces.Box(low=np.array([-np.inf, -np.pi, 0, -1, 0]),\n",
    "                                            high=np.array([np.inf, np.pi, np.inf, 1, 1]),\n",
    "                                            dtype=np.float32)\n",
    "        \n",
    "        self.route = None\n",
    "        self.wp_index = 0\n",
    "\n",
    "        self.previous_location = None\n",
    "        self.previous_timestamp = None\n",
    "        self.previous_distance = None\n",
    "\n",
    "        self.max_steps = 2000\n",
    "        self.step_count = 0\n",
    "\n",
    "\n",
    "    def reset(self, seed = None, options = None):\n",
    "        self.socket.send(pickle.dumps({\"command\": \"reset\"}))\n",
    "        \n",
    "        response = pickle.loads(self.socket.recv())\n",
    "        # print(response)\n",
    "        if response[\"status\"] != \"reset done\":\n",
    "            raise RuntimeError(f\"Server reset failed check port cur port {self.port}\")\n",
    "        \n",
    "        obs = response[\"observation\"] \n",
    "        self.route = [Location(x, y) for [x, y] in response[\"route\"]]\n",
    "        self.wp_index = 0\n",
    "\n",
    "        image = decode_image(obs[\"image\"])\n",
    "        _, lane_deviation, obstacle_proximity = process_frame(image)\n",
    "        state = self.get_state(obs, lane_deviation, obstacle_proximity)\n",
    "\n",
    "        self.previous_location = self.get_current_location(obs)\n",
    "        self.previous_timestamp = obs[\"timestamp\"]\n",
    "        self.previous_distance = self.get_distance_to_waypoint(obs)\n",
    "        self.previous_steer = 0\n",
    "        self.step_count=0\n",
    "\n",
    "        return state, {}\n",
    "    \n",
    "    def step(self, action):\n",
    "        self.socket.send(pickle.dumps({\"action\": action.tolist()}))\n",
    "        obs = pickle.loads(self.socket.recv())\n",
    "\n",
    "        image = decode_image(obs[\"image\"])\n",
    "        processed_image, lane_deviation, obstacle_proximity = process_frame(image)\n",
    "        state = self.get_state(obs, lane_deviation, obstacle_proximity)\n",
    "\n",
    "        reward = self.compute_reward(obs, lane_deviation, obstacle_proximity, action[0])\n",
    "\n",
    "        if obs[\"collision\"] is not None:\n",
    "            print(\"Collision detected, respawning...\")\n",
    "            state, _ = self.reset()\n",
    "            reward -= 100\n",
    "\n",
    "        else:\n",
    "            state = self.get_state(obs, lane_deviation, obstacle_proximity)\n",
    "\n",
    "        terminated = self.is_terminated(obs)\n",
    "        truncated = self.is_truncated()\n",
    "\n",
    "        self.step_count += 1\n",
    "\n",
    "        self.previous_location = self.get_current_location(obs)\n",
    "        self.previous_timestamp = obs[\"timestamp\"]\n",
    "        self.previous_distance = self.get_distance_to_waypoint(obs)\n",
    "        self.previous_steer = action[0]\n",
    "\n",
    "        return state, reward, terminated, truncated, {}\n",
    "    \n",
    "    def get_current_location(self, obs):\n",
    "        lat, lon = obs[\"gnss\"][\"latitude\"], obs[\"gnss\"][\"longitude\"]\n",
    "        x = -14418.6285 * lat + 111279.5690 * lon - 3.19252014\n",
    "        y = -109660.6210 * lat + 4.33686914 * lon + 0.367254638\n",
    "        return Location(x, y)\n",
    "    \n",
    "    def get_state(self, obs, lane_deviation, obstacle_proximity):\n",
    "        current_loc = self.get_current_location(obs)\n",
    "\n",
    "        if self.wp_index < len(self.route):\n",
    "            next_wp_loc = self.route[self.wp_index]\n",
    "            distance = current_loc.distance(next_wp_loc) / 100.0\n",
    "            vehicle_yaw = quaternion_to_yaw(obs[\"imu\"][\"orientation\"])\n",
    "            delta_x = next_wp_loc.x - current_loc.x\n",
    "            delta_y = next_wp_loc.y - current_loc.y\n",
    "            desired_yaw = np.arctan2(delta_y, delta_x)\n",
    "            angle_to_way_point = normalize_angle(desired_yaw - vehicle_yaw)\n",
    "        else:\n",
    "            distance = 0\n",
    "            angle_to_way_point = 0\n",
    "        \n",
    "        if self.previous_location is not None and self.previous_timestamp < obs[\"timestamp\"]:\n",
    "            time_elapsed = obs[\"timestamp\"] - self.previous_timestamp\n",
    "            distance_travelled = current_loc.distance(self.previous_location)\n",
    "            speed = (distance_travelled / time_elapsed if time_elapsed > 0 else 0) /20.0\n",
    "        else:\n",
    "            speed = 0\n",
    "\n",
    "        return np.array([distance, angle_to_way_point, speed, lane_deviation, obstacle_proximity], dtype=np.float32)\n",
    "    \n",
    "    def get_distance_to_waypoint(self, obs):\n",
    "        current_loc = self.get_current_location(obs)\n",
    "        if self.wp_index < len(self.route):\n",
    "            next_wp_loc = self.route[self.wp_index]\n",
    "            return current_loc.distance(next_wp_loc)\n",
    "        return 0\n",
    "    \n",
    "    def compute_reward(self, obs, lane_deviation, obstacle_proximity, steer):\n",
    "        current_distance = self.get_distance_to_waypoint(obs)\n",
    "        progress = self.previous_distance - current_distance\n",
    "        reward = progress\n",
    "\n",
    "        reward -= 0.1 * abs(lane_deviation)\n",
    "\n",
    "        if obstacle_proximity > 0.5:\n",
    "            reward -= (obstacle_proximity - 0.5) * 20\n",
    "        \n",
    "        if obs[\"collision\"] is not None:\n",
    "            reward -= 100\n",
    "\n",
    "        if obs[\"lane_invaded\"][\"violated\"]:\n",
    "            reward -= 10\n",
    "\n",
    "        speed = self.get_state(obs, lane_deviation, obstacle_proximity)[2] * 20.0\n",
    "        if speed < 5 or speed > 10:\n",
    "            reward -= 0.1\n",
    "        else:\n",
    "            reward += 0.1\n",
    "\n",
    "        steer_change = abs(steer - self.previous_steer)\n",
    "        if steer_change > 0.2:\n",
    "            reward -= steer_change * 5\n",
    "\n",
    "        return reward\n",
    "    \n",
    "    \n",
    "    def is_terminated(self, obs):\n",
    "        if self.wp_index >= len(self.route):\n",
    "            return True\n",
    "        \n",
    "        current_distance = self.get_distance_to_waypoint(obs)\n",
    "        if self.wp_index == len(self.route) - 1 and current_distance < 5.0:\n",
    "            print(\"Near final waypoint, success\")\n",
    "            return True\n",
    "        elif current_distance < 2.0:\n",
    "            self.wp_index += 1\n",
    "            if self.wp_index >= len(self.route):\n",
    "                return True\n",
    "        \n",
    "        return False\n",
    "    \n",
    "    def is_truncated(self):\n",
    "        return self.step_count >= self.max_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    env = CarlaEnv(port=6501)\n",
    "    checkpoint_path = 'checkpoints/carla_rl_model_50000_steps.zip'\n",
    "\n",
    "    if os.path.exists(checkpoint_path):\n",
    "        model = PPO.load(checkpoint_path, env=env)\n",
    "        print(f\"Resuming training from checkpoint: {checkpoint_path}\")\n",
    "    else:\n",
    "        model = PPO(\n",
    "            \"MlpPolicy\",\n",
    "            env,\n",
    "            verbose=1,\n",
    "            n_steps=2048,\n",
    "            batch_size=64,\n",
    "            n_epochs=10,\n",
    "            gamma=0.99,\n",
    "            learning_rate=3e-4,\n",
    "            gae_lambda=0.95,\n",
    "            ent_coef=0.01\n",
    "        )\n",
    "        print(\"Starting new training.\")\n",
    "\n",
    "    check_point_callback = CheckpointCallback(save_freq=50000, save_path='./checkpoints/', name_prefix='carla_rl_model')\n",
    "\n",
    "    total_timesteps = 5000000\n",
    "\n",
    "    model.learn(total_timesteps=total_timesteps, callback=check_point_callback, progress_bar=False)\n",
    "\n",
    "    model.save(\"carla_rl_agent\")\n",
    "\n",
    "# import ray\n",
    "# from ray.tune.registry import register_env\n",
    "# from ray.rllib.algorithms.ppo import PPO as RayPPO\n",
    "# import gymnasium as gym\n",
    "# import torch\n",
    "# import os\n",
    "\n",
    "\n",
    "# def env_creator(env_config):\n",
    "#     return CarlaEnv(port=env_config[\"port\"])\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     if torch.cuda.is_available():\n",
    "#         print(f\"Using GPU: {torch.cuda.get_device_name(0)}\")\n",
    "#     else:\n",
    "#         raise RuntimeError(\"CUDA not available, GPU required for multi-PC training\")\n",
    "\n",
    "#     ray.init(address=\"auto\" if \"RAY_HEAD_IP\" not in os.environ else f\"{os.environ['RAY_HEAD_IP']}:6379\")\n",
    "\n",
    "#     register_env(\"carla_env\", env_creator)\n",
    "\n",
    "#     config = {\n",
    "#         \"env\": \"carla_env\",\n",
    "#         \"num_workers\": 8,  # 4 per PC\n",
    "#         \"num_gpus\": 2,     # 1 per PC\n",
    "#         \"num_cpus\": 32,    # 16 per PC\n",
    "#         \"framework\": \"torch\",\n",
    "#         \"train_batch_size\": 2048 * 8,  # Scaled for 8 envs\n",
    "#         \"sgd_minibatch_size\": 64,\n",
    "#         \"num_sgd_iter\": 10,\n",
    "#         \"lr\": 3e-4,\n",
    "#         \"gamma\": 0.99,\n",
    "#         \"lambda\": 0.95,\n",
    "#         \"entropy_coeff\": 0.01,\n",
    "#         \"env_config\": {\"port\": ray.tune.grid_search([6501, 6502, 6503, 6504, 6505, 6506, 6507, 6508])},\n",
    "#         \"model\": {\n",
    "#             \"custom_model\": None,  # Use default MLP\n",
    "#         },\n",
    "#     }\n",
    "\n",
    "#     algo = RayPPO(config=config)\n",
    "\n",
    "#     total_timesteps = 5000000\n",
    "#     steps_trained = 0\n",
    "#     while steps_trained < total_timesteps:\n",
    "#         result = algo.train()\n",
    "#         steps_trained = result[\"timesteps_total\"]\n",
    "#         print(f\"Steps: {steps_trained}, Reward: {result['episode_reward_mean']}\")\n",
    "#         if steps_trained % 50000 == 0:\n",
    "#             checkpoint = algo.save(\"./ray_checkpoints\")\n",
    "#             print(f\"Checkpoint saved: {checkpoint}\")\n",
    "\n",
    "#     algo.save(\"./ray_final_model\")\n",
    "#     ray.shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs, _ = env.reset()\n",
    "for _ in range(1000):\n",
    "    action, _ = model.predict(obs, deterministic=True)\n",
    "    obs, reward, terminated, truncated, info = env.step(action)\n",
    "    image = decode_image(obs[\"image\"])\n",
    "    processed_img, _, _ = process_frame(image) \n",
    "    cv2.imshow(\"Processed Image\", processed_img)\n",
    "    print(f\"Action: {action}, Reward: {reward}, Terminated: {terminated}, Truncated: {truncated}\")\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "    if terminated or truncated:\n",
    "        obs, _ = env.reset()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.6.0+cu124\n",
      "CUDA available: True\n",
      "GPU: NVIDIA RTX 5000 Ada Generation\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(\"PyTorch version:\", torch.__version__)\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "if torch.cuda.is_available():\n",
    "    print(\"GPU:\", torch.cuda.get_device_name(0))\n",
    "else:\n",
    "    print(\"CUDA not available\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "context = zmq.Context()\n",
    "socket = context.socket(zmq.REQ)\n",
    "socket.connect(\"tcp://localhost:6501\")\n",
    "\n",
    "def send_action(steer: float, throttle: float):\n",
    "    action = {\n",
    "        \"action\": [steer, throttle]\n",
    "    }\n",
    "    socket.send(pickle.dumps(action))  \n",
    "    response = socket.recv()           \n",
    "    data = pickle.loads(response)      \n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "\n",
    "def decode_image(image_bytes):\n",
    "    np_arr = np.frombuffer(image_bytes, dtype=np.uint8)\n",
    "    img = cv2.imdecode(np_arr, cv2.IMREAD_COLOR)\n",
    "    return img\n",
    "\n",
    "for step in range(200):\n",
    "    steer = 0\n",
    "    throttle = -1\n",
    "    obs = send_action(steer, throttle)\n",
    "\n",
    "    # Extract observation\n",
    "    # try:\n",
    "    image = decode_image(obs[\"image\"])\n",
    "    gnss = obs[\"gnss\"]\n",
    "    collision = obs[\"collision\"]\n",
    "    imu = obs[\"imu\"]\n",
    "    timestamp = obs[\"timestamp\"]\n",
    "    lane_invaded = obs[\"lane_invaded\"]\n",
    "    \n",
    "    procsses_image = process_frame(image)\n",
    "    \n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        quit = True\n",
    "        break\n",
    "    \n",
    "    # print(f\"[Step {step}] GNSS: {gnss} | Time: {timestamp} | Collision: {collision} | imu: {imu} | lane: {lane_invaded}\")\n",
    "    # # print(f\"lane: {lane_invaded}\")\n",
    "    # if lane_invaded['violated'] == True:\n",
    "    #     print(lane_invaded[\"last_event\"])\n",
    "    #     print(lane_invaded)\n",
    "        # cv2.imshow(\"Invasion\", image)\n",
    "\n",
    "    # Optional: show image\n",
    "    cv2.imshow(\"Camera\", procsses_image)\n",
    "    # cv2.imshow(\"Camera1\", image)\n",
    "    cv2.waitKey(1)\n",
    "\n",
    "    # except Exception as e:\n",
    "    #     print(lane_invaded[\"last_event\"])\n",
    "    #     print(lane_invaded)\n",
    "    #     print(e)\n",
    "    #     # print(f\"[ERROR] Failed to process observation: {e}\")\n",
    "    #     # print(f\"[DEBUG] Image shape before processing: {image.shape}\")\n",
    "    #     pass\n",
    "    #     # break\n",
    "\n",
    "    # time.sleep(0.05) \n",
    "cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_command = {\"command\": \"reset\"}\n",
    "socket.send(pickle.dumps(reset_command))\n",
    "_ = socket.recv()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "carla_rl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
