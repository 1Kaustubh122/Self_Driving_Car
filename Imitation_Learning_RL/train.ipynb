{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1b238b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import json\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "# from torchvision.models import resnet18\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torch.utils.data import Dataset, DataLoader, random_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "12fd5a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImitationDataset(Dataset):\n",
    "    def __init__(self, rgb_dir, seg_dir, log_path, transforms=None):\n",
    "        self.rgb_dir = rgb_dir\n",
    "        self.seg_dir = seg_dir\n",
    "        self.log_path = log_path\n",
    "        self.transform = transforms\n",
    "        \n",
    "        with open(log_path, 'r') as f:\n",
    "            self.log_data = json.load(f)\n",
    "            \n",
    "    def __len__(self):\n",
    "        return len(self.log_data)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        rgb_image_path = os.path.join(self.rgb_dir, f\"{index:05d}.png\")\n",
    "        seg_image_path = os.path.join(self.seg_dir, f\"{index:05d}.png\")\n",
    "        \n",
    "        rgb_image = Image.open(rgb_image_path)\n",
    "        \n",
    "        if self.transform:\n",
    "            rgb_tensor = self.transform(rgb_image)\n",
    "        else:\n",
    "            rgb_tensor = transforms.ToTensor()(rgb_image)\n",
    "            \n",
    "        seg_image = np.array(Image.open(seg_image_path))\n",
    "        \n",
    "        lane_mask = np.all(seg_image == [0, 255, 0], axis=2).astype(np.uint8)\n",
    "        obs_mask = np.all(seg_image == [255, 0, 0], axis=2).astype(np.uint8)\n",
    "        \n",
    "        seg_tensor = torch.tensor(np.stack([lane_mask, obs_mask], axis=0), dtype=torch.float32)\n",
    "        \n",
    "        if seg_tensor.shape[1:] != rgb_tensor.shape[1:]:\n",
    "            seg_tensor = F.interpolate(\n",
    "                seg_tensor.unsqueeze(0),\n",
    "                size=rgb_tensor.shape[1:],\n",
    "                mode='nearest'\n",
    "            ).squeeze(0)\n",
    "        \n",
    "        input_tensor = torch.cat([rgb_tensor, seg_tensor], dim=0)\n",
    "                        \n",
    "        control = self.log_data[index]\n",
    "        control_tensor = torch.tensor([\n",
    "            control['steer'],\n",
    "            control['throttle'],\n",
    "            control['brake']\n",
    "        ], dtype=torch.float32)\n",
    "        \n",
    "        return input_tensor, control_tensor\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d9cfbb21",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImitationCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ImitationCNN, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(5, 32, kernel_size=5, stride=2, padding=2)  \n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=2, padding=1)  \n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, stride=2, padding=1) \n",
    "        self.conv4 = nn.Conv2d(128, 256, kernel_size=3, stride=2, padding=1)\n",
    "\n",
    "        self.fc = nn.Linear(256 * 23 * 40, 512) \n",
    "        \n",
    "        # Output: steer, throttle, brake\n",
    "        self.steer_head = nn.Linear(512, 1)\n",
    "        self.throttle_head = nn.Linear(512, 1)  \n",
    "        self.brake_head = nn.Linear(512, 1)    \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = F.relu(self.conv4(x))\n",
    "        \n",
    "        x = x.view(x.size(0), -1)  \n",
    "        x = F.relu(self.fc(x))\n",
    "        \n",
    "        steer = self.steer_head(x)\n",
    "        throttle = self.throttle_head(x)\n",
    "        brake = self.brake_head(x)\n",
    "        \n",
    "        return torch.cat([steer, throttle, brake], dim=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c481bcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Loss: 0.0408\n",
      "[VAL] Steer MSE: 0.0501, Throttle RMSE: 0.0886, Brake RMSE: 0.0717\n",
      "Epoch [2/100], Loss: 0.0166\n",
      "[VAL] Steer MSE: 0.0433, Throttle RMSE: 0.0853, Brake RMSE: 0.0713\n",
      "Epoch [3/100], Loss: 0.0132\n",
      "[VAL] Steer MSE: 0.0426, Throttle RMSE: 0.0809, Brake RMSE: 0.0625\n",
      "Epoch [4/100], Loss: 0.0106\n",
      "[VAL] Steer MSE: 0.0402, Throttle RMSE: 0.0851, Brake RMSE: 0.0706\n",
      "Epoch [5/100], Loss: 0.0081\n",
      "[VAL] Steer MSE: 0.0397, Throttle RMSE: 0.0808, Brake RMSE: 0.0638\n",
      "Epoch [6/100], Loss: 0.0056\n",
      "[VAL] Steer MSE: 0.0403, Throttle RMSE: 0.0919, Brake RMSE: 0.0699\n",
      "Epoch [7/100], Loss: 0.0040\n",
      "[VAL] Steer MSE: 0.0380, Throttle RMSE: 0.0862, Brake RMSE: 0.0634\n",
      "Epoch [8/100], Loss: 0.0030\n",
      "[VAL] Steer MSE: 0.0380, Throttle RMSE: 0.0861, Brake RMSE: 0.0645\n",
      "Epoch [9/100], Loss: 0.0021\n",
      "[VAL] Steer MSE: 0.0374, Throttle RMSE: 0.0833, Brake RMSE: 0.0617\n",
      "Epoch [10/100], Loss: 0.0015\n",
      "[VAL] Steer MSE: 0.0378, Throttle RMSE: 0.0823, Brake RMSE: 0.0623\n",
      "Epoch [11/100], Loss: 0.0012\n",
      "[VAL] Steer MSE: 0.0374, Throttle RMSE: 0.0835, Brake RMSE: 0.0630\n",
      "Epoch [12/100], Loss: 0.0009\n",
      "[VAL] Steer MSE: 0.0373, Throttle RMSE: 0.0859, Brake RMSE: 0.0649\n",
      "Epoch [13/100], Loss: 0.0009\n",
      "[VAL] Steer MSE: 0.0376, Throttle RMSE: 0.0853, Brake RMSE: 0.0644\n",
      "Epoch [14/100], Loss: 0.0009\n",
      "[VAL] Steer MSE: 0.0374, Throttle RMSE: 0.0838, Brake RMSE: 0.0632\n",
      "Epoch [15/100], Loss: 0.0010\n"
     ]
    }
   ],
   "source": [
    "rgb_dir = 'rgb_image'\n",
    "seg_dir = 'seg_image'\n",
    "log_path = 'logs/logs.json'\n",
    "\n",
    "os.makedirs('checkpoints', exist_ok=True)\n",
    "\n",
    "dataset = ImitationDataset(rgb_dir, seg_dir, log_path, None)\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "train_set, val_set = torch.utils.data.random_split(dataset, [train_size, val_size])\n",
    "train_loader = DataLoader(train_set, 32, shuffle=True)\n",
    "val_loader = DataLoader(val_set, 32, shuffle=False)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = ImitationCNN().to(device)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "num_epochs = 100\n",
    "\n",
    "best_rmse = float('inf')\n",
    "train_losses = []\n",
    "val_steer, val_throttle, val_brake = [], [], []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    for i, (inputs, targets) in enumerate(train_loader):\n",
    "        inputs = inputs.to(device)\n",
    "        targets = targets.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs= model(inputs)\n",
    "        loss_steer = F.mse_loss(outputs[:, 0], targets[:, 0])\n",
    "        loss_throttle = F.smooth_l1_loss(outputs[:, 1], targets[:, 1])\n",
    "        loss_brake = F.smooth_l1_loss(outputs[:, 2], targets[:, 2])\n",
    "        \n",
    "        loss = loss_steer + 2.0 * (loss_throttle + loss_brake) \n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader):.4f}\")\n",
    "    model.eval()\n",
    "    total_se, total_th, total_br = 0, 0, 0\n",
    "    n=0\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in val_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            targets = targets.to(device)\n",
    "            outputs = model(inputs)\n",
    "            \n",
    "            total_se += F.mse_loss(outputs[:, 0], targets[:, 0], reduction='sum').item()\n",
    "            total_th += F.mse_loss(outputs[:, 1], targets[:, 1], reduction='sum').item()\n",
    "            total_br += F.mse_loss(outputs[:, 2], targets[:, 2], reduction='sum').item()\n",
    "            n+= inputs.size(0)\n",
    "            \n",
    "    val_rmse = ((total_se +total_th + total_br)/(3*n)) **0.5\n",
    "    \n",
    "    if val_rmse < best_rmse:\n",
    "        best_rmse = val_rmse\n",
    "        torch.save(model.state_dict(), 'checkpoints/best_model.pth')\n",
    "    \n",
    "    torch.save(model.state_dict(), 'checkpoints/last_epoch.pth')\n",
    "    \n",
    "    val_st = (total_se/n)**0.5     \n",
    "    val_th = (total_th/n)**0.5     \n",
    "    val_br = (total_br/n)**0.5\n",
    "    \n",
    "    train_losses.append(running_loss/len(train_loader))\n",
    "    val_steer.append(val_st)\n",
    "    val_throttle.append(val_th)\n",
    "    val_brake.append(val_br)\n",
    "    \n",
    "    \n",
    "    print(f\"[VAL] Steer MSE: {val_st:.4f}, Throttle RMSE: {val_th:.4f}, Brake RMSE: {val_br:.4f}\")\n",
    "    \n",
    "    with open('logs/val_metrics.csv', 'a') as f:\n",
    "        f.write(f\"{epoch+1},{val_st:.4f},{val_th:.4f},{val_br:.4f}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3489f79d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(train_losses, label='Train Loss')\n",
    "plt.plot(val_steer, label='Val Steer RMSE')\n",
    "plt.plot(val_throttle, label='Val Throttle RMSE')\n",
    "plt.plot(val_brake, label='Val Brake RMSE')\n",
    "plt.legend()\n",
    "plt.savefig('training_curves.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1dffbedc",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m torch\u001b[38;5;241m.\u001b[39msave(\u001b[43mmodel\u001b[49m\u001b[38;5;241m.\u001b[39mstate_dict(), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel.pth\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      2\u001b[0m model\u001b[38;5;241m.\u001b[39meval()  \u001b[38;5;66;03m# Set the model to evaluation mode\u001b[39;00m\n\u001b[1;32m      3\u001b[0m steer_error \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "torch.save(model.state_dict(), 'model.pth')\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "steer_error = 0\n",
    "throttle_error = 0\n",
    "brake_error = 0\n",
    "\n",
    "with torch.no_grad():  # No gradient calculation during evaluation\n",
    "    for inputs, targets in train_loader:  # Using train_loader for demonstration\n",
    "        inputs = inputs.to(device)\n",
    "        targets = targets.to(device)\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        steer_error += F.mse_loss(outputs[:, 0], targets[:, 0], reduction='sum').item()\n",
    "        throttle_error += F.mse_loss(outputs[:, 1], targets[:, 1], reduction='sum').item()\n",
    "        brake_error += F.mse_loss(outputs[:, 2], targets[:, 2], reduction='sum').item()\n",
    "\n",
    "n = len(train_loader.dataset)  # Total number of samples in the dataset\n",
    "\n",
    "print(f\"Steer MSE: {steer_error/n:.4f}, Throttle MSE: {throttle_error/n:.4f}, Brake MSE: {brake_error/n:.4f}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3add3721",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "with open('logs/logs.json') as f:\n",
    "    log = json.load(f)\n",
    "\n",
    "train_log, val_log = train_test_split(log, test_size=0.2, random_state=42)\n",
    "\n",
    "with open('train_log.json', 'w') as f:\n",
    "    json.dump(train_log, f)\n",
    "with open('val_log.json', 'w') as f:\n",
    "    json.dump(val_log, f, indent=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "52c8dcf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "rgb_dir = 'rgb_image'\n",
    "seg_dir = 'seg_image'\n",
    "transform = None\n",
    "# transform = transforms.Compose([\n",
    "#     transforms.Resize((128, 128)),\n",
    "#     transforms.ToTensor(),\n",
    "# ])\n",
    "train_dataset = ImitationDataset(rgb_dir, seg_dir, 'train_log.json', transform)\n",
    "val_dataset = ImitationDataset(rgb_dir, seg_dir, 'val_log.json', transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5737c88b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[VAL] Steer MSE: 0.007455, Throttle MSE: 0.121155, Brake MSE: 0.211377\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "steer_error = 0\n",
    "throttle_error = 0\n",
    "brake_error = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, targets in val_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        targets = targets.to(device)\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        steer_error += F.mse_loss(outputs[:, 0], targets[:, 0], reduction='sum').item()\n",
    "        throttle_error += F.mse_loss(outputs[:, 1], targets[:, 1], reduction='sum').item()\n",
    "        brake_error += F.mse_loss(outputs[:, 2], targets[:, 2], reduction='sum').item()\n",
    "\n",
    "n = len(val_loader.dataset)\n",
    "print(f\"[VAL] Steer MSE: {steer_error/n:.6f}, Throttle MSE: {throttle_error/n:.6f}, Brake MSE: {brake_error/n:.6f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3c322b10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[VAL] Steer RMSE: 0.086340, Throttle RMSE: 0.348074, Brake RMSE: 0.459758\n"
     ]
    }
   ],
   "source": [
    "steer_rmse = (steer_error / n) ** 0.5\n",
    "throttle_rmse = (throttle_error / n) ** 0.5\n",
    "brake_rmse = (brake_error / n) ** 0.5\n",
    "\n",
    "print(f\"[VAL] Steer RMSE: {steer_rmse:.6f}, Throttle RMSE: {throttle_rmse:.6f}, Brake RMSE: {brake_rmse:.6f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1470c773",
   "metadata": {},
   "outputs": [],
   "source": [
    "# seg_image_path = Image.open(\"seg_image/00000.png\")\n",
    "# rgb_image_path = Image.open(\"rgb_image/00000.png\")\n",
    "\n",
    "# # rgb_image = cv2.cvtColor(cv2.imread(rgb_image_path), cv2.COLOR_BGR2RGB)\n",
    "# # rgb_image = Image.fromarray(rgb_image)\n",
    "\n",
    "\n",
    "# # rgb_tensor = transforms.ToTensor()(rgb_image)\n",
    "# rgb_image = np.array(rgb_image_path)\n",
    "\n",
    "# # Convert RGB image to RGB format (if needed)\n",
    "# rgb_image = cv2.cvtColor(rgb_image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# # Convert the numpy array to a PIL Image (if needed)\n",
    "# rgb_image = Image.fromarray(rgb_image)\n",
    "\n",
    "# # Convert RGB image to tensor\n",
    "# rgb_tensor = transforms.ToTensor()(rgb_image)\n",
    "\n",
    "# seg_image = np.array(seg_image_path)\n",
    "# lane_mask = np.all(seg_image == [0, 255, 0], axis=2).astype(np.uint8)\n",
    "# obs_mask = np.all(seg_image == [255, 0, 0], axis=2).astype(np.uint8)\n",
    "# seg_tensor = torch.tensor(np.stack([lane_mask, obs_mask], axis=0), dtype=torch.float32)\n",
    "\n",
    "# if seg_tensor.shape[1:] != rgb_tensor.shape[1:]:\n",
    "#     seg_tensor = F.interpolate(\n",
    "#         seg_tensor.unsqueeze(0),\n",
    "#         size=rgb_tensor.shape[1:],\n",
    "#         mode='nearest'\n",
    "#     ).squeeze(0)\n",
    "\n",
    "# input_tensor = torch.cat([rgb_tensor, seg_tensor], dim=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "carla_15",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
